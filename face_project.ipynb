{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8+HaD//Q5sFTm9khYt8q/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vangogh1803/face_rec/blob/main/face_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGUpI73NNboF",
        "outputId": "14b71e9e-f270-4301-dd54-d56b654ba2e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = \"/content/drive/MyDrive/face_proj\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset, Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "dZUBkHy2Q9ak"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1wBrxT9Rew7",
        "outputId": "f06b8b47-2883-4dfe-cc2e-628f6cba12a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n"
      ],
      "metadata": {
        "id": "9awkkYh-Xet7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "3vOLWV_Edzq3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list | head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftt1gIhFW4VA",
        "outputId": "cc2afc4a-fd99-4466-e7bc-da341e306a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                  title                                           size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "---------------------------------------------------  ----------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "neurocipher/heartdisease                             Heart Disease                                   3491  2025-12-11 15:29:14.327000           2114        204  1.0              \n",
            "ahmeduzaki/wind-and-solar-energy-production-dataset  Wind & Solar Energy Production Dataset        395372  2026-01-02 21:06:22.780000              0         35  1.0              \n",
            "kundanbedmutha/exam-score-prediction-dataset         Exam Score Prediction Dataset                 325454  2025-11-28 07:29:01.047000           5863        249  1.0              \n",
            "guriya79/heart-failure-prediction-dataset            Heart Failure Clinical Records Study            4067  2025-12-27 05:13:37.790000              0         28  1.0              \n",
            "neurocipher/student-performance                      Student Performance                            49705  2025-12-12 12:06:28.973000           1261        120  1.0              \n",
            "ishank2005/salary-csv                                Salary.csv                                       392  2025-12-29 15:48:58.240000              0         27  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                Melbourne Housing Snapshot                    461423  2018-06-05 12:52:24.087000         200095       1722  0.7058824        \n",
            "datasnaek/youtube-new                                Trending YouTube Video Statistics          210575746  2019-06-03 00:56:47.177000         292850       5843  0.7941176        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kenny3s/casia-webface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuErHUOMECec",
        "outputId": "2485be7c-d61d-41be-817b-f4988c4f070d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kenny3s/casia-webface\n",
            "License(s): MIT\n",
            "casia-webface.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jessicali9530/lfw-dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJMsw19Aejo8",
        "outputId": "d0501267-dd96-49cf-ee27-15d8092221dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/lfw-dataset\n",
            "License(s): other\n",
            "Downloading lfw-dataset.zip to /content\n",
            "  0% 0.00/112M [00:00<?, ?B/s]\n",
            "100% 112M/112M [00:00<00:00, 1.31GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Jw2gyorigoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/data/lfw-dataset.zip -d /content/data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osuXbaXLezNw",
        "outputId": "f7a887e3-5cb1-4556-f22b-93cd0c99ff44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/data/lfw-dataset.zip, /content/data/lfw-dataset.zip.zip or /content/data/lfw-dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/casia-webface.zip -d /content/data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUeceF4JFlop",
        "outputId": "da61ab9e-10f1-4a2c-d403-e43a3c5fee1c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/casia-webface.zip\n",
            "replace /content/data/datasets/0000045/001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Build identity â†’ image indices map\n",
        "id_to_indices = defaultdict(list)\n",
        "for idx, lbl in enumerate(dataset.targets):\n",
        "    id_to_indices[lbl].append(idx)\n",
        "\n",
        "# Keep identities with >= 2 images\n",
        "valid_ids = [lbl for lbl, idxs in id_to_indices.items() if len(idxs) >= 2]\n",
        "print(\"Valid identities:\", len(valid_ids))\n",
        "\n",
        "# Split identities\n",
        "random.shuffle(valid_ids)\n",
        "split = int(0.8 * len(valid_ids))\n",
        "\n",
        "train_ids = valid_ids[:split]\n",
        "val_ids   = valid_ids[split:]\n",
        "\n",
        "# Build index lists\n",
        "train_idx, val_idx = [], []\n",
        "\n",
        "for lbl in train_ids:\n",
        "    train_idx.extend(id_to_indices[lbl])\n",
        "\n",
        "for lbl in val_ids:\n",
        "    val_idx.extend(id_to_indices[lbl])\n",
        "\n",
        "print(\"Train images:\", len(train_idx))\n",
        "print(\"Val images:\", len(val_idx))\n",
        "\n",
        "# Build datasets\n",
        "train_dataset = Subset(dataset, train_idx)\n",
        "val_dataset   = Subset(dataset, val_idx)\n"
      ],
      "metadata": {
        "id": "QQTozuQLQxWd",
        "outputId": "60dedfc6-7bf8-4407-b8ab-4df74c9ce022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid identities: 700\n",
            "Train images: 13127\n",
            "Val images: 3292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader=DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "1rV3adeYRBFR"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet-pytorch\n"
      ],
      "metadata": {
        "id": "evX_LhaymGMQ",
        "outputId": "b9520b4a-6d32-41e2-fcb8-ebcba9124cce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.12/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (1.26.4)\n",
            "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (10.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (2.32.4)\n",
            "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (2.2.2)\n",
            "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (0.17.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "mtcnn = MTCNN(\n",
        "    image_size=224,\n",
        "    margin=20,\n",
        "    keep_all=False,\n",
        "    device=device\n",
        ")\n"
      ],
      "metadata": {
        "id": "rjnKaWcCnqDp"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class FaceDetectDataset(Dataset):\n",
        "    def __init__(self, base_dataset, mtcnn):\n",
        "        self.base_dataset = base_dataset\n",
        "        self.mtcnn = mtcnn\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.base_dataset[idx]\n",
        "\n",
        "        # ensure PIL image\n",
        "        if isinstance(img, torch.Tensor):\n",
        "            img = transforms.ToPILImage()(img)\n",
        "\n",
        "        # detect face\n",
        "        face = self.mtcnn(img)\n",
        "\n",
        "        if face is None:\n",
        "            # fallback: resize original image\n",
        "            face = transforms.Resize((224,224))(img)\n",
        "            face = transforms.ToTensor()(face)\n",
        "        else:\n",
        "            # face is already tensor\n",
        "            face = face\n",
        "\n",
        "        return face, label\n"
      ],
      "metadata": {
        "id": "4QWqHLiCn8AS"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Classification*"
      ],
      "metadata": {
        "id": "5B-6YrhPYonw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((112, 112)),   # IMPORTANT (see next point)\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.5, 0.5, 0.5],\n",
        "        std=[0.5, 0.5, 0.5]\n",
        "    )\n",
        "])\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.Grayscale(num_output_channels=3),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(\n",
        "#         mean=[0.485, 0.456, 0.406],\n",
        "#         std=[0.229, 0.224, 0.225]\n",
        "#     )\n",
        "# ])\n",
        "##augmentation\n",
        "# from torchvision import transforms\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.RandomHorizontalFlip(p=0.5),\n",
        "#     transforms.RandomApply([\n",
        "#         transforms.ColorJitter(\n",
        "#             brightness=0.2,\n",
        "#             contrast=0.2,\n",
        "#             saturation=0.2\n",
        "#         )\n",
        "#     ], p=0.5),\n",
        "#     transforms.RandomGrayscale(p=0.1),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(\n",
        "#         mean=[0.485, 0.456, 0.406],\n",
        "#         std=[0.229, 0.224, 0.225]\n",
        "#     )\n",
        "# ])\n"
      ],
      "metadata": {
        "id": "Zk7h0UqVXm2N"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/data -maxdepth 3 -type d | head -n 20\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATC4NalhH1c_",
        "outputId": "2ae42ef1-a74c-463c-f975-aa8132ffb953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n",
            "/content/data/casia_dev\n",
            "/content/data/casia_dev/0000696\n",
            "/content/data/casia_dev/0000981\n",
            "/content/data/casia_dev/0000422\n",
            "/content/data/casia_dev/0000948\n",
            "/content/data/casia_dev/0000675\n",
            "/content/data/casia_dev/0000260\n",
            "/content/data/casia_dev/0000996\n",
            "/content/data/casia_dev/0000304\n",
            "/content/data/casia_dev/0000880\n",
            "/content/data/casia_dev/0000570\n",
            "/content/data/casia_dev/0000275\n",
            "/content/data/casia_dev/0000670\n",
            "/content/data/casia_dev/0000616\n",
            "/content/data/casia_dev/0000615\n",
            "/content/data/casia_dev/0000133\n",
            "/content/data/casia_dev/0000394\n",
            "/content/data/casia_dev/0000836\n",
            "/content/data/casia_dev/0000373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/data/datasets\"\n",
        "\n",
        "dataset = datasets.ImageFolder(\n",
        "    root=dataset_path,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(\"Total images:\", len(dataset))\n",
        "print(\"Total identities:\", len(dataset.classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vby43vWPZFLA",
        "outputId": "c3f140ef-0bfd-486e-fbc0-ed6594637149"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 452960\n",
            "Total identities: 10575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEV_IDENTITIES = 800\n",
        "IMAGES_PER_ID = 25\n",
        "import os, shutil\n",
        "from collections import defaultdict\n",
        "\n",
        "SRC = \"/content/data/datasets\"\n",
        "DST = \"/content/data/casia_dev\"\n",
        "\n",
        "os.makedirs(DST, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "QDXPYc61RdLT"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "identities = sorted(os.listdir(SRC))[:DEV_IDENTITIES]\n",
        "\n",
        "for ident in identities:\n",
        "    src_id = os.path.join(SRC, ident)\n",
        "    dst_id = os.path.join(DST, ident)\n",
        "    os.makedirs(dst_id, exist_ok=True)\n",
        "\n",
        "    imgs = os.listdir(src_id)[:IMAGES_PER_ID]\n",
        "    for img in imgs:\n",
        "        shutil.copy(\n",
        "            os.path.join(src_id, img),\n",
        "            os.path.join(dst_id, img)\n",
        "        )\n",
        "\n",
        "print(\"CASIA dev subset ready\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fm8mTUvRp0o",
        "outputId": "cfbfc305-1069-47d9-e0c0-3a505d09056e"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CASIA dev subset ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/data/casia_dev\"\n",
        "\n",
        "dataset = datasets.ImageFolder(\n",
        "    root=dataset_path,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(\"Images:\", len(dataset))\n",
        "print(\"Identities:\", len(dataset.classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0jvQ0wbRuiL",
        "outputId": "ecace844-693d-48e1-fe1f-27480f0f9af5"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images: 18556\n",
            "Identities: 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size=int(0.8*len(dataset))\n",
        "val_size=len(dataset)-train_size\n",
        "train_dataset, val_dataset=torch.utils.data.random_split(\n",
        "    dataset, [train_size, val_size]\n",
        "  )\n"
      ],
      "metadata": {
        "id": "yfftQrDQaHR9"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "import random\n",
        "\n",
        "labels = dataset.targets\n",
        "id_to_idx = {}\n",
        "\n",
        "for i, lbl in enumerate(labels):\n",
        "    id_to_idx.setdefault(lbl, []).append(i)\n",
        "\n",
        "ids = list(id_to_idx.keys())\n",
        "random.shuffle(ids)\n",
        "\n",
        "split = int(0.8 * len(ids))\n",
        "train_ids = ids[:split]\n",
        "val_ids = ids[split:]\n",
        "\n",
        "train_idx, val_idx = [], []\n",
        "\n",
        "for i in train_ids:\n",
        "    train_idx.extend(id_to_idx[i])\n",
        "\n",
        "for i in val_ids:\n",
        "    val_idx.extend(id_to_idx[i])\n",
        "\n",
        "train_dataset = Subset(dataset, train_idx)\n",
        "val_dataset = Subset(dataset, val_idx)\n"
      ],
      "metadata": {
        "id": "JAbnvfTVSPbJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "5Uwp6EltTa4h"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=models.resnet18(pretrained=True)\n",
        "model.fc=nn.Linear(model.fc.in_features, len(dataset.classes))\n",
        "model=model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp11mrF4gMzp",
        "outputId": "fcd274ed-2416-4261-8972-448931476e52"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "aLZK0WB9g3E4"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train now:\n",
        "Epochs=3\n",
        "for epoch in range(Epochs):\n",
        "  model.train()\n",
        "  running_loss=0\n",
        "  correct=0\n",
        "  total=0\n",
        "\n",
        "  for images, labels in train_loader:\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output=model(images)\n",
        "    loss=criterion(output, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss+=loss.item()\n",
        "    _, preds=torch.max(output, 1)\n",
        "    correct+=(preds==labels).sum().item()\n",
        "    total+=labels.size(0)\n",
        "\n",
        "    train_acc=100*correct/total\n",
        "    print(f\"Epoch [{epoch+1}/{Epochs}] \"\n",
        "          f\"Loss: {running_loss:.3f} | Train Acc: {train_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsqbRrLVhF2Z",
        "outputId": "deccef5e-faac-4e2f-a5ba-9b33bb12154f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3] Loss: 6.796 | Train Acc: 1.56%\n",
            "Epoch [1/3] Loss: 13.667 | Train Acc: 0.78%\n",
            "Epoch [1/3] Loss: 20.551 | Train Acc: 0.52%\n",
            "Epoch [1/3] Loss: 27.242 | Train Acc: 0.78%\n",
            "Epoch [1/3] Loss: 34.026 | Train Acc: 0.62%\n",
            "Epoch [1/3] Loss: 40.871 | Train Acc: 0.52%\n",
            "Epoch [1/3] Loss: 47.664 | Train Acc: 0.45%\n",
            "Epoch [1/3] Loss: 54.411 | Train Acc: 0.39%\n",
            "Epoch [1/3] Loss: 61.257 | Train Acc: 0.52%\n",
            "Epoch [1/3] Loss: 68.223 | Train Acc: 0.47%\n",
            "Epoch [1/3] Loss: 75.006 | Train Acc: 0.43%\n",
            "Epoch [1/3] Loss: 81.789 | Train Acc: 0.39%\n",
            "Epoch [1/3] Loss: 88.614 | Train Acc: 0.36%\n",
            "Epoch [1/3] Loss: 95.600 | Train Acc: 0.45%\n",
            "Epoch [1/3] Loss: 102.281 | Train Acc: 0.42%\n",
            "Epoch [1/3] Loss: 108.931 | Train Acc: 0.39%\n",
            "Epoch [1/3] Loss: 115.573 | Train Acc: 0.37%\n",
            "Epoch [1/3] Loss: 122.341 | Train Acc: 0.35%\n",
            "Epoch [1/3] Loss: 128.984 | Train Acc: 0.33%\n",
            "Epoch [1/3] Loss: 135.653 | Train Acc: 0.31%\n",
            "Epoch [1/3] Loss: 142.359 | Train Acc: 0.30%\n",
            "Epoch [1/3] Loss: 148.877 | Train Acc: 0.28%\n",
            "Epoch [1/3] Loss: 155.410 | Train Acc: 0.27%\n",
            "Epoch [1/3] Loss: 162.013 | Train Acc: 0.26%\n",
            "Epoch [1/3] Loss: 168.810 | Train Acc: 0.31%\n",
            "Epoch [1/3] Loss: 175.501 | Train Acc: 0.30%\n",
            "Epoch [1/3] Loss: 182.020 | Train Acc: 0.29%\n",
            "Epoch [1/3] Loss: 188.442 | Train Acc: 0.33%\n",
            "Epoch [1/3] Loss: 195.135 | Train Acc: 0.32%\n",
            "Epoch [1/3] Loss: 201.862 | Train Acc: 0.31%\n",
            "Epoch [1/3] Loss: 208.531 | Train Acc: 0.30%\n",
            "Epoch [1/3] Loss: 215.157 | Train Acc: 0.29%\n",
            "Epoch [1/3] Loss: 221.788 | Train Acc: 0.28%\n",
            "Epoch [1/3] Loss: 228.320 | Train Acc: 0.28%\n",
            "Epoch [1/3] Loss: 234.770 | Train Acc: 0.27%\n",
            "Epoch [1/3] Loss: 241.448 | Train Acc: 0.26%\n",
            "Epoch [1/3] Loss: 247.837 | Train Acc: 0.25%\n",
            "Epoch [1/3] Loss: 254.528 | Train Acc: 0.25%\n",
            "Epoch [1/3] Loss: 261.120 | Train Acc: 0.28%\n",
            "Epoch [1/3] Loss: 267.600 | Train Acc: 0.27%\n",
            "Epoch [1/3] Loss: 274.117 | Train Acc: 0.30%\n",
            "Epoch [1/3] Loss: 280.541 | Train Acc: 0.33%\n",
            "Epoch [1/3] Loss: 287.020 | Train Acc: 0.36%\n",
            "Epoch [1/3] Loss: 293.512 | Train Acc: 0.36%\n",
            "Epoch [1/3] Loss: 299.934 | Train Acc: 0.38%\n",
            "Epoch [1/3] Loss: 306.433 | Train Acc: 0.37%\n",
            "Epoch [1/3] Loss: 312.622 | Train Acc: 0.40%\n",
            "Epoch [1/3] Loss: 319.033 | Train Acc: 0.39%\n",
            "Epoch [1/3] Loss: 325.370 | Train Acc: 0.38%\n",
            "Epoch [1/3] Loss: 331.850 | Train Acc: 0.38%\n",
            "Epoch [1/3] Loss: 338.174 | Train Acc: 0.40%\n",
            "Epoch [1/3] Loss: 344.459 | Train Acc: 0.42%\n",
            "Epoch [1/3] Loss: 350.836 | Train Acc: 0.44%\n",
            "Epoch [1/3] Loss: 357.068 | Train Acc: 0.46%\n",
            "Epoch [1/3] Loss: 363.537 | Train Acc: 0.45%\n",
            "Epoch [1/3] Loss: 369.879 | Train Acc: 0.45%\n",
            "Epoch [1/3] Loss: 376.292 | Train Acc: 0.47%\n",
            "Epoch [1/3] Loss: 382.625 | Train Acc: 0.46%\n",
            "Epoch [1/3] Loss: 388.975 | Train Acc: 0.48%\n",
            "Epoch [1/3] Loss: 395.339 | Train Acc: 0.52%\n",
            "Epoch [1/3] Loss: 401.895 | Train Acc: 0.51%\n",
            "Epoch [1/3] Loss: 408.088 | Train Acc: 0.55%\n",
            "Epoch [1/3] Loss: 414.409 | Train Acc: 0.60%\n",
            "Epoch [1/3] Loss: 420.611 | Train Acc: 0.61%\n",
            "Epoch [1/3] Loss: 427.033 | Train Acc: 0.65%\n",
            "Epoch [1/3] Loss: 433.471 | Train Acc: 0.66%\n",
            "Epoch [1/3] Loss: 439.766 | Train Acc: 0.65%\n",
            "Epoch [1/3] Loss: 446.043 | Train Acc: 0.67%\n",
            "Epoch [1/3] Loss: 452.352 | Train Acc: 0.68%\n",
            "Epoch [1/3] Loss: 458.689 | Train Acc: 0.67%\n",
            "Epoch [1/3] Loss: 465.058 | Train Acc: 0.68%\n",
            "Epoch [1/3] Loss: 471.336 | Train Acc: 0.67%\n",
            "Epoch [1/3] Loss: 477.584 | Train Acc: 0.66%\n",
            "Epoch [1/3] Loss: 483.711 | Train Acc: 0.72%\n",
            "Epoch [1/3] Loss: 489.993 | Train Acc: 0.73%\n",
            "Epoch [1/3] Loss: 496.346 | Train Acc: 0.78%\n",
            "Epoch [1/3] Loss: 502.732 | Train Acc: 0.77%\n",
            "Epoch [1/3] Loss: 508.948 | Train Acc: 0.80%\n",
            "Epoch [1/3] Loss: 515.153 | Train Acc: 0.81%\n",
            "Epoch [1/3] Loss: 521.260 | Train Acc: 0.80%\n",
            "Epoch [1/3] Loss: 527.450 | Train Acc: 0.81%\n",
            "Epoch [1/3] Loss: 533.596 | Train Acc: 0.82%\n",
            "Epoch [1/3] Loss: 539.785 | Train Acc: 0.83%\n",
            "Epoch [1/3] Loss: 546.005 | Train Acc: 0.84%\n",
            "Epoch [1/3] Loss: 552.295 | Train Acc: 0.85%\n",
            "Epoch [1/3] Loss: 558.658 | Train Acc: 0.84%\n",
            "Epoch [1/3] Loss: 564.764 | Train Acc: 0.86%\n",
            "Epoch [1/3] Loss: 571.130 | Train Acc: 0.85%\n",
            "Epoch [1/3] Loss: 577.217 | Train Acc: 0.86%\n",
            "Epoch [1/3] Loss: 583.443 | Train Acc: 0.85%\n",
            "Epoch [1/3] Loss: 589.618 | Train Acc: 0.86%\n",
            "Epoch [1/3] Loss: 595.866 | Train Acc: 0.85%\n",
            "Epoch [1/3] Loss: 602.174 | Train Acc: 0.84%\n",
            "Epoch [1/3] Loss: 608.363 | Train Acc: 0.86%\n",
            "Epoch [1/3] Loss: 614.588 | Train Acc: 0.87%\n",
            "Epoch [1/3] Loss: 620.723 | Train Acc: 0.90%\n",
            "Epoch [1/3] Loss: 626.990 | Train Acc: 0.90%\n",
            "Epoch [1/3] Loss: 633.138 | Train Acc: 0.91%\n",
            "Epoch [1/3] Loss: 639.342 | Train Acc: 0.93%\n",
            "Epoch [1/3] Loss: 645.604 | Train Acc: 0.94%\n",
            "Epoch [1/3] Loss: 651.874 | Train Acc: 0.93%\n",
            "Epoch [1/3] Loss: 657.988 | Train Acc: 0.92%\n",
            "Epoch [1/3] Loss: 663.921 | Train Acc: 0.97%\n",
            "Epoch [1/3] Loss: 670.019 | Train Acc: 0.98%\n",
            "Epoch [1/3] Loss: 676.084 | Train Acc: 1.00%\n",
            "Epoch [1/3] Loss: 682.318 | Train Acc: 1.00%\n",
            "Epoch [1/3] Loss: 688.426 | Train Acc: 1.04%\n",
            "Epoch [1/3] Loss: 694.565 | Train Acc: 1.07%\n",
            "Epoch [1/3] Loss: 700.582 | Train Acc: 1.10%\n",
            "Epoch [1/3] Loss: 706.725 | Train Acc: 1.11%\n",
            "Epoch [1/3] Loss: 712.740 | Train Acc: 1.13%\n",
            "Epoch [1/3] Loss: 718.899 | Train Acc: 1.12%\n",
            "Epoch [1/3] Loss: 724.935 | Train Acc: 1.16%\n",
            "Epoch [1/3] Loss: 730.851 | Train Acc: 1.15%\n",
            "Epoch [1/3] Loss: 737.031 | Train Acc: 1.15%\n",
            "Epoch [1/3] Loss: 742.890 | Train Acc: 1.24%\n",
            "Epoch [1/3] Loss: 748.961 | Train Acc: 1.23%\n",
            "Epoch [1/3] Loss: 755.074 | Train Acc: 1.24%\n",
            "Epoch [1/3] Loss: 761.016 | Train Acc: 1.27%\n",
            "Epoch [1/3] Loss: 767.045 | Train Acc: 1.28%\n",
            "Epoch [1/3] Loss: 773.019 | Train Acc: 1.28%\n",
            "Epoch [1/3] Loss: 778.942 | Train Acc: 1.27%\n",
            "Epoch [1/3] Loss: 784.897 | Train Acc: 1.27%\n",
            "Epoch [1/3] Loss: 791.057 | Train Acc: 1.29%\n",
            "Epoch [1/3] Loss: 797.069 | Train Acc: 1.29%\n",
            "Epoch [1/3] Loss: 803.126 | Train Acc: 1.29%\n",
            "Epoch [1/3] Loss: 809.167 | Train Acc: 1.29%\n",
            "Epoch [1/3] Loss: 815.240 | Train Acc: 1.32%\n",
            "Epoch [1/3] Loss: 821.213 | Train Acc: 1.33%\n",
            "Epoch [1/3] Loss: 827.234 | Train Acc: 1.36%\n",
            "Epoch [1/3] Loss: 833.301 | Train Acc: 1.36%\n",
            "Epoch [1/3] Loss: 839.312 | Train Acc: 1.35%\n",
            "Epoch [1/3] Loss: 845.234 | Train Acc: 1.36%\n",
            "Epoch [1/3] Loss: 851.121 | Train Acc: 1.42%\n",
            "Epoch [1/3] Loss: 857.104 | Train Acc: 1.47%\n",
            "Epoch [1/3] Loss: 862.990 | Train Acc: 1.46%\n",
            "Epoch [1/3] Loss: 869.038 | Train Acc: 1.46%\n",
            "Epoch [1/3] Loss: 874.957 | Train Acc: 1.47%\n",
            "Epoch [1/3] Loss: 880.900 | Train Acc: 1.48%\n",
            "Epoch [1/3] Loss: 887.029 | Train Acc: 1.48%\n",
            "Epoch [1/3] Loss: 892.869 | Train Acc: 1.50%\n",
            "Epoch [1/3] Loss: 898.771 | Train Acc: 1.53%\n",
            "Epoch [1/3] Loss: 904.694 | Train Acc: 1.53%\n",
            "Epoch [1/3] Loss: 910.750 | Train Acc: 1.52%\n",
            "Epoch [1/3] Loss: 916.587 | Train Acc: 1.55%\n",
            "Epoch [1/3] Loss: 922.555 | Train Acc: 1.56%\n",
            "Epoch [1/3] Loss: 928.340 | Train Acc: 1.57%\n",
            "Epoch [1/3] Loss: 934.247 | Train Acc: 1.62%\n",
            "Epoch [1/3] Loss: 940.459 | Train Acc: 1.60%\n",
            "Epoch [1/3] Loss: 946.425 | Train Acc: 1.62%\n",
            "Epoch [1/3] Loss: 952.211 | Train Acc: 1.65%\n",
            "Epoch [1/3] Loss: 958.072 | Train Acc: 1.66%\n",
            "Epoch [1/3] Loss: 963.903 | Train Acc: 1.66%\n",
            "Epoch [1/3] Loss: 969.657 | Train Acc: 1.67%\n",
            "Epoch [1/3] Loss: 975.361 | Train Acc: 1.70%\n",
            "Epoch [1/3] Loss: 981.255 | Train Acc: 1.72%\n",
            "Epoch [1/3] Loss: 987.145 | Train Acc: 1.73%\n",
            "Epoch [1/3] Loss: 992.998 | Train Acc: 1.76%\n",
            "Epoch [1/3] Loss: 998.681 | Train Acc: 1.79%\n",
            "Epoch [1/3] Loss: 1004.615 | Train Acc: 1.80%\n",
            "Epoch [1/3] Loss: 1010.294 | Train Acc: 1.86%\n",
            "Epoch [1/3] Loss: 1016.148 | Train Acc: 1.88%\n",
            "Epoch [1/3] Loss: 1021.985 | Train Acc: 1.89%\n",
            "Epoch [1/3] Loss: 1027.713 | Train Acc: 1.89%\n",
            "Epoch [1/3] Loss: 1033.405 | Train Acc: 1.93%\n",
            "Epoch [1/3] Loss: 1039.190 | Train Acc: 1.95%\n",
            "Epoch [1/3] Loss: 1045.066 | Train Acc: 1.96%\n",
            "Epoch [1/3] Loss: 1050.933 | Train Acc: 1.95%\n",
            "Epoch [1/3] Loss: 1056.379 | Train Acc: 1.98%\n",
            "Epoch [1/3] Loss: 1062.138 | Train Acc: 1.99%\n",
            "Epoch [1/3] Loss: 1067.866 | Train Acc: 2.00%\n",
            "Epoch [1/3] Loss: 1073.603 | Train Acc: 2.00%\n",
            "Epoch [1/3] Loss: 1079.368 | Train Acc: 2.01%\n",
            "Epoch [1/3] Loss: 1085.067 | Train Acc: 2.03%\n",
            "Epoch [1/3] Loss: 1090.862 | Train Acc: 2.04%\n",
            "Epoch [1/3] Loss: 1096.484 | Train Acc: 2.07%\n",
            "Epoch [1/3] Loss: 1102.410 | Train Acc: 2.06%\n",
            "Epoch [1/3] Loss: 1108.257 | Train Acc: 2.07%\n",
            "Epoch [1/3] Loss: 1114.074 | Train Acc: 2.09%\n",
            "Epoch [1/3] Loss: 1119.905 | Train Acc: 2.09%\n",
            "Epoch [1/3] Loss: 1125.609 | Train Acc: 2.09%\n",
            "Epoch [1/3] Loss: 1131.240 | Train Acc: 2.10%\n",
            "Epoch [1/3] Loss: 1136.970 | Train Acc: 2.13%\n",
            "Epoch [1/3] Loss: 1142.724 | Train Acc: 2.14%\n",
            "Epoch [1/3] Loss: 1148.316 | Train Acc: 2.16%\n",
            "Epoch [1/3] Loss: 1154.198 | Train Acc: 2.17%\n",
            "Epoch [1/3] Loss: 1159.732 | Train Acc: 2.21%\n",
            "Epoch [1/3] Loss: 1165.521 | Train Acc: 2.22%\n",
            "Epoch [1/3] Loss: 1171.078 | Train Acc: 2.24%\n",
            "Epoch [1/3] Loss: 1176.755 | Train Acc: 2.25%\n",
            "Epoch [1/3] Loss: 1182.357 | Train Acc: 2.27%\n",
            "Epoch [1/3] Loss: 1188.262 | Train Acc: 2.28%\n",
            "Epoch [1/3] Loss: 1193.806 | Train Acc: 2.29%\n",
            "Epoch [1/3] Loss: 1199.325 | Train Acc: 2.34%\n",
            "Epoch [1/3] Loss: 1204.985 | Train Acc: 2.36%\n",
            "Epoch [1/3] Loss: 1210.613 | Train Acc: 2.38%\n",
            "Epoch [1/3] Loss: 1216.320 | Train Acc: 2.38%\n",
            "Epoch [1/3] Loss: 1221.885 | Train Acc: 2.39%\n",
            "Epoch [1/3] Loss: 1227.379 | Train Acc: 2.41%\n",
            "Epoch [1/3] Loss: 1232.853 | Train Acc: 2.44%\n",
            "Epoch [1/3] Loss: 1238.488 | Train Acc: 2.46%\n",
            "Epoch [1/3] Loss: 1244.059 | Train Acc: 2.46%\n",
            "Epoch [1/3] Loss: 1249.720 | Train Acc: 2.48%\n",
            "Epoch [1/3] Loss: 1255.252 | Train Acc: 2.52%\n",
            "Epoch [1/3] Loss: 1260.934 | Train Acc: 2.53%\n",
            "Epoch [2/3] Loss: 5.204 | Train Acc: 12.50%\n",
            "Epoch [2/3] Loss: 10.307 | Train Acc: 12.50%\n",
            "Epoch [2/3] Loss: 15.415 | Train Acc: 11.98%\n",
            "Epoch [2/3] Loss: 20.571 | Train Acc: 14.84%\n",
            "Epoch [2/3] Loss: 25.938 | Train Acc: 13.44%\n",
            "Epoch [2/3] Loss: 31.175 | Train Acc: 13.28%\n",
            "Epoch [2/3] Loss: 36.338 | Train Acc: 13.39%\n",
            "Epoch [2/3] Loss: 41.489 | Train Acc: 13.87%\n",
            "Epoch [2/3] Loss: 46.556 | Train Acc: 14.06%\n",
            "Epoch [2/3] Loss: 51.749 | Train Acc: 14.22%\n",
            "Epoch [2/3] Loss: 56.757 | Train Acc: 14.35%\n",
            "Epoch [2/3] Loss: 62.010 | Train Acc: 14.45%\n",
            "Epoch [2/3] Loss: 67.186 | Train Acc: 14.42%\n",
            "Epoch [2/3] Loss: 72.263 | Train Acc: 14.40%\n",
            "Epoch [2/3] Loss: 77.629 | Train Acc: 14.17%\n",
            "Epoch [2/3] Loss: 82.743 | Train Acc: 14.36%\n",
            "Epoch [2/3] Loss: 87.773 | Train Acc: 14.61%\n",
            "Epoch [2/3] Loss: 93.129 | Train Acc: 14.24%\n",
            "Epoch [2/3] Loss: 98.326 | Train Acc: 14.23%\n",
            "Epoch [2/3] Loss: 103.291 | Train Acc: 14.38%\n",
            "Epoch [2/3] Loss: 108.417 | Train Acc: 14.51%\n",
            "Epoch [2/3] Loss: 113.469 | Train Acc: 14.42%\n",
            "Epoch [2/3] Loss: 118.620 | Train Acc: 14.47%\n",
            "Epoch [2/3] Loss: 123.650 | Train Acc: 14.52%\n",
            "Epoch [2/3] Loss: 128.804 | Train Acc: 14.62%\n",
            "Epoch [2/3] Loss: 133.984 | Train Acc: 14.60%\n",
            "Epoch [2/3] Loss: 138.992 | Train Acc: 14.58%\n",
            "Epoch [2/3] Loss: 143.985 | Train Acc: 14.68%\n",
            "Epoch [2/3] Loss: 148.912 | Train Acc: 14.66%\n",
            "Epoch [2/3] Loss: 154.104 | Train Acc: 14.69%\n",
            "Epoch [2/3] Loss: 159.139 | Train Acc: 14.67%\n",
            "Epoch [2/3] Loss: 164.347 | Train Acc: 14.60%\n",
            "Epoch [2/3] Loss: 169.348 | Train Acc: 14.68%\n",
            "Epoch [2/3] Loss: 174.110 | Train Acc: 14.80%\n",
            "Epoch [2/3] Loss: 179.109 | Train Acc: 15.04%\n",
            "Epoch [2/3] Loss: 184.151 | Train Acc: 15.10%\n",
            "Epoch [2/3] Loss: 189.152 | Train Acc: 15.16%\n",
            "Epoch [2/3] Loss: 194.184 | Train Acc: 15.13%\n",
            "Epoch [2/3] Loss: 199.406 | Train Acc: 15.02%\n",
            "Epoch [2/3] Loss: 204.587 | Train Acc: 15.00%\n",
            "Epoch [2/3] Loss: 209.505 | Train Acc: 15.28%\n",
            "Epoch [2/3] Loss: 214.295 | Train Acc: 15.44%\n",
            "Epoch [2/3] Loss: 219.482 | Train Acc: 15.37%\n",
            "Epoch [2/3] Loss: 224.448 | Train Acc: 15.45%\n",
            "Epoch [2/3] Loss: 229.228 | Train Acc: 15.76%\n",
            "Epoch [2/3] Loss: 234.137 | Train Acc: 15.69%\n",
            "Epoch [2/3] Loss: 239.280 | Train Acc: 15.49%\n",
            "Epoch [2/3] Loss: 244.222 | Train Acc: 15.49%\n",
            "Epoch [2/3] Loss: 249.102 | Train Acc: 15.69%\n",
            "Epoch [2/3] Loss: 253.924 | Train Acc: 15.81%\n",
            "Epoch [2/3] Loss: 259.217 | Train Acc: 15.81%\n",
            "Epoch [2/3] Loss: 264.279 | Train Acc: 15.69%\n",
            "Epoch [2/3] Loss: 269.055 | Train Acc: 15.86%\n",
            "Epoch [2/3] Loss: 274.025 | Train Acc: 15.91%\n",
            "Epoch [2/3] Loss: 278.848 | Train Acc: 15.94%\n",
            "Epoch [2/3] Loss: 284.010 | Train Acc: 15.93%\n",
            "Epoch [2/3] Loss: 289.204 | Train Acc: 15.87%\n",
            "Epoch [2/3] Loss: 294.198 | Train Acc: 15.89%\n",
            "Epoch [2/3] Loss: 299.345 | Train Acc: 15.81%\n",
            "Epoch [2/3] Loss: 304.378 | Train Acc: 15.89%\n",
            "Epoch [2/3] Loss: 309.163 | Train Acc: 15.88%\n",
            "Epoch [2/3] Loss: 313.957 | Train Acc: 15.88%\n",
            "Epoch [2/3] Loss: 318.906 | Train Acc: 15.82%\n",
            "Epoch [2/3] Loss: 323.855 | Train Acc: 15.82%\n",
            "Epoch [2/3] Loss: 328.852 | Train Acc: 15.82%\n",
            "Epoch [2/3] Loss: 333.853 | Train Acc: 15.84%\n",
            "Epoch [2/3] Loss: 338.600 | Train Acc: 16.02%\n",
            "Epoch [2/3] Loss: 343.419 | Train Acc: 15.97%\n",
            "Epoch [2/3] Loss: 348.534 | Train Acc: 15.85%\n",
            "Epoch [2/3] Loss: 353.548 | Train Acc: 15.89%\n",
            "Epoch [2/3] Loss: 358.672 | Train Acc: 15.89%\n",
            "Epoch [2/3] Loss: 363.797 | Train Acc: 15.78%\n",
            "Epoch [2/3] Loss: 368.562 | Train Acc: 15.86%\n",
            "Epoch [2/3] Loss: 373.387 | Train Acc: 15.92%\n",
            "Epoch [2/3] Loss: 378.456 | Train Acc: 15.92%\n",
            "Epoch [2/3] Loss: 383.661 | Train Acc: 15.87%\n",
            "Epoch [2/3] Loss: 388.709 | Train Acc: 15.85%\n",
            "Epoch [2/3] Loss: 393.624 | Train Acc: 15.85%\n",
            "Epoch [2/3] Loss: 398.432 | Train Acc: 15.84%\n",
            "Epoch [2/3] Loss: 403.478 | Train Acc: 15.90%\n",
            "Epoch [2/3] Loss: 408.338 | Train Acc: 15.90%\n",
            "Epoch [2/3] Loss: 413.115 | Train Acc: 15.95%\n",
            "Epoch [2/3] Loss: 418.197 | Train Acc: 15.89%\n",
            "Epoch [2/3] Loss: 423.235 | Train Acc: 15.92%\n",
            "Epoch [2/3] Loss: 428.090 | Train Acc: 15.99%\n",
            "Epoch [2/3] Loss: 432.960 | Train Acc: 15.99%\n",
            "Epoch [2/3] Loss: 437.843 | Train Acc: 16.04%\n",
            "Epoch [2/3] Loss: 442.826 | Train Acc: 15.98%\n",
            "Epoch [2/3] Loss: 447.915 | Train Acc: 15.96%\n",
            "Epoch [2/3] Loss: 452.727 | Train Acc: 15.99%\n",
            "Epoch [2/3] Loss: 457.355 | Train Acc: 16.11%\n",
            "Epoch [2/3] Loss: 462.552 | Train Acc: 16.12%\n",
            "Epoch [2/3] Loss: 467.623 | Train Acc: 16.15%\n",
            "Epoch [2/3] Loss: 472.449 | Train Acc: 16.14%\n",
            "Epoch [2/3] Loss: 477.368 | Train Acc: 16.10%\n",
            "Epoch [2/3] Loss: 482.188 | Train Acc: 16.13%\n",
            "Epoch [2/3] Loss: 487.104 | Train Acc: 16.16%\n",
            "Epoch [2/3] Loss: 492.049 | Train Acc: 16.17%\n",
            "Epoch [2/3] Loss: 496.908 | Train Acc: 16.19%\n",
            "Epoch [2/3] Loss: 501.585 | Train Acc: 16.28%\n",
            "Epoch [2/3] Loss: 506.534 | Train Acc: 16.27%\n",
            "Epoch [2/3] Loss: 511.341 | Train Acc: 16.30%\n",
            "Epoch [2/3] Loss: 516.177 | Train Acc: 16.29%\n",
            "Epoch [2/3] Loss: 520.795 | Train Acc: 16.38%\n",
            "Epoch [2/3] Loss: 525.635 | Train Acc: 16.40%\n",
            "Epoch [2/3] Loss: 530.591 | Train Acc: 16.42%\n",
            "Epoch [2/3] Loss: 535.362 | Train Acc: 16.50%\n",
            "Epoch [2/3] Loss: 540.399 | Train Acc: 16.46%\n",
            "Epoch [2/3] Loss: 545.615 | Train Acc: 16.44%\n",
            "Epoch [2/3] Loss: 550.293 | Train Acc: 16.49%\n",
            "Epoch [2/3] Loss: 555.175 | Train Acc: 16.50%\n",
            "Epoch [2/3] Loss: 560.085 | Train Acc: 16.53%\n",
            "Epoch [2/3] Loss: 564.897 | Train Acc: 16.57%\n",
            "Epoch [2/3] Loss: 569.824 | Train Acc: 16.57%\n",
            "Epoch [2/3] Loss: 574.559 | Train Acc: 16.63%\n",
            "Epoch [2/3] Loss: 579.444 | Train Acc: 16.65%\n",
            "Epoch [2/3] Loss: 584.315 | Train Acc: 16.68%\n",
            "Epoch [2/3] Loss: 589.085 | Train Acc: 16.74%\n",
            "Epoch [2/3] Loss: 593.938 | Train Acc: 16.70%\n",
            "Epoch [2/3] Loss: 598.622 | Train Acc: 16.77%\n",
            "Epoch [2/3] Loss: 603.320 | Train Acc: 16.84%\n",
            "Epoch [2/3] Loss: 608.186 | Train Acc: 16.87%\n",
            "Epoch [2/3] Loss: 613.133 | Train Acc: 16.86%\n",
            "Epoch [2/3] Loss: 617.945 | Train Acc: 16.87%\n",
            "Epoch [2/3] Loss: 622.918 | Train Acc: 16.88%\n",
            "Epoch [2/3] Loss: 627.769 | Train Acc: 16.87%\n",
            "Epoch [2/3] Loss: 632.659 | Train Acc: 16.84%\n",
            "Epoch [2/3] Loss: 637.450 | Train Acc: 16.88%\n",
            "Epoch [2/3] Loss: 642.058 | Train Acc: 16.93%\n",
            "Epoch [2/3] Loss: 646.781 | Train Acc: 16.96%\n",
            "Epoch [2/3] Loss: 651.444 | Train Acc: 17.00%\n",
            "Epoch [2/3] Loss: 656.366 | Train Acc: 17.00%\n",
            "Epoch [2/3] Loss: 661.176 | Train Acc: 17.02%\n",
            "Epoch [2/3] Loss: 665.896 | Train Acc: 17.01%\n",
            "Epoch [2/3] Loss: 670.889 | Train Acc: 17.03%\n",
            "Epoch [2/3] Loss: 675.485 | Train Acc: 17.10%\n",
            "Epoch [2/3] Loss: 680.318 | Train Acc: 17.13%\n",
            "Epoch [2/3] Loss: 685.069 | Train Acc: 17.16%\n",
            "Epoch [2/3] Loss: 689.470 | Train Acc: 17.25%\n",
            "Epoch [2/3] Loss: 693.938 | Train Acc: 17.34%\n",
            "Epoch [2/3] Loss: 698.657 | Train Acc: 17.35%\n",
            "Epoch [2/3] Loss: 703.319 | Train Acc: 17.36%\n",
            "Epoch [2/3] Loss: 708.228 | Train Acc: 17.34%\n",
            "Epoch [2/3] Loss: 713.078 | Train Acc: 17.37%\n",
            "Epoch [2/3] Loss: 717.904 | Train Acc: 17.38%\n",
            "Epoch [2/3] Loss: 722.771 | Train Acc: 17.37%\n",
            "Epoch [2/3] Loss: 727.396 | Train Acc: 17.43%\n",
            "Epoch [2/3] Loss: 732.113 | Train Acc: 17.44%\n",
            "Epoch [2/3] Loss: 736.878 | Train Acc: 17.45%\n",
            "Epoch [2/3] Loss: 741.448 | Train Acc: 17.47%\n",
            "Epoch [2/3] Loss: 746.098 | Train Acc: 17.50%\n",
            "Epoch [2/3] Loss: 750.904 | Train Acc: 17.49%\n",
            "Epoch [2/3] Loss: 755.461 | Train Acc: 17.50%\n",
            "Epoch [2/3] Loss: 760.338 | Train Acc: 17.50%\n",
            "Epoch [2/3] Loss: 765.009 | Train Acc: 17.55%\n",
            "Epoch [2/3] Loss: 769.811 | Train Acc: 17.55%\n",
            "Epoch [2/3] Loss: 774.394 | Train Acc: 17.59%\n",
            "Epoch [2/3] Loss: 779.101 | Train Acc: 17.58%\n",
            "Epoch [2/3] Loss: 783.774 | Train Acc: 17.59%\n",
            "Epoch [2/3] Loss: 788.366 | Train Acc: 17.59%\n",
            "Epoch [2/3] Loss: 792.956 | Train Acc: 17.60%\n",
            "Epoch [2/3] Loss: 797.920 | Train Acc: 17.61%\n",
            "Epoch [2/3] Loss: 802.624 | Train Acc: 17.65%\n",
            "Epoch [2/3] Loss: 807.340 | Train Acc: 17.68%\n",
            "Epoch [2/3] Loss: 812.205 | Train Acc: 17.70%\n",
            "Epoch [2/3] Loss: 816.743 | Train Acc: 17.71%\n",
            "Epoch [2/3] Loss: 821.232 | Train Acc: 17.76%\n",
            "Epoch [2/3] Loss: 825.992 | Train Acc: 17.74%\n",
            "Epoch [2/3] Loss: 830.491 | Train Acc: 17.78%\n",
            "Epoch [2/3] Loss: 834.944 | Train Acc: 17.82%\n",
            "Epoch [2/3] Loss: 839.525 | Train Acc: 17.85%\n",
            "Epoch [2/3] Loss: 844.224 | Train Acc: 17.87%\n",
            "Epoch [2/3] Loss: 848.482 | Train Acc: 17.96%\n",
            "Epoch [2/3] Loss: 853.190 | Train Acc: 17.96%\n",
            "Epoch [2/3] Loss: 857.690 | Train Acc: 18.00%\n",
            "Epoch [2/3] Loss: 862.186 | Train Acc: 18.04%\n",
            "Epoch [2/3] Loss: 866.984 | Train Acc: 18.04%\n",
            "Epoch [2/3] Loss: 871.381 | Train Acc: 18.11%\n",
            "Epoch [2/3] Loss: 875.875 | Train Acc: 18.17%\n",
            "Epoch [2/3] Loss: 880.241 | Train Acc: 18.25%\n",
            "Epoch [2/3] Loss: 884.739 | Train Acc: 18.27%\n",
            "Epoch [2/3] Loss: 889.040 | Train Acc: 18.33%\n",
            "Epoch [2/3] Loss: 893.766 | Train Acc: 18.31%\n",
            "Epoch [2/3] Loss: 898.555 | Train Acc: 18.29%\n",
            "Epoch [2/3] Loss: 902.907 | Train Acc: 18.34%\n",
            "Epoch [2/3] Loss: 907.532 | Train Acc: 18.39%\n",
            "Epoch [2/3] Loss: 912.180 | Train Acc: 18.37%\n",
            "Epoch [2/3] Loss: 916.842 | Train Acc: 18.38%\n",
            "Epoch [2/3] Loss: 921.407 | Train Acc: 18.37%\n",
            "Epoch [2/3] Loss: 926.137 | Train Acc: 18.36%\n",
            "Epoch [2/3] Loss: 930.626 | Train Acc: 18.37%\n",
            "Epoch [2/3] Loss: 935.222 | Train Acc: 18.36%\n",
            "Epoch [2/3] Loss: 939.911 | Train Acc: 18.38%\n",
            "Epoch [2/3] Loss: 944.593 | Train Acc: 18.38%\n",
            "Epoch [2/3] Loss: 949.088 | Train Acc: 18.43%\n",
            "Epoch [2/3] Loss: 953.526 | Train Acc: 18.46%\n",
            "Epoch [2/3] Loss: 958.337 | Train Acc: 18.47%\n",
            "Epoch [2/3] Loss: 962.930 | Train Acc: 18.50%\n",
            "Epoch [2/3] Loss: 967.570 | Train Acc: 18.50%\n",
            "Epoch [2/3] Loss: 972.232 | Train Acc: 18.52%\n",
            "Epoch [2/3] Loss: 976.511 | Train Acc: 18.59%\n",
            "Epoch [2/3] Loss: 981.109 | Train Acc: 18.60%\n",
            "Epoch [2/3] Loss: 985.727 | Train Acc: 18.61%\n",
            "Epoch [2/3] Loss: 990.283 | Train Acc: 18.64%\n",
            "Epoch [2/3] Loss: 994.956 | Train Acc: 18.65%\n",
            "Epoch [3/3] Loss: 3.894 | Train Acc: 45.31%\n",
            "Epoch [3/3] Loss: 8.070 | Train Acc: 39.06%\n",
            "Epoch [3/3] Loss: 12.096 | Train Acc: 38.02%\n",
            "Epoch [3/3] Loss: 16.026 | Train Acc: 37.11%\n",
            "Epoch [3/3] Loss: 19.994 | Train Acc: 36.56%\n",
            "Epoch [3/3] Loss: 23.951 | Train Acc: 37.76%\n",
            "Epoch [3/3] Loss: 28.100 | Train Acc: 36.83%\n",
            "Epoch [3/3] Loss: 32.264 | Train Acc: 35.55%\n",
            "Epoch [3/3] Loss: 36.119 | Train Acc: 36.11%\n",
            "Epoch [3/3] Loss: 39.815 | Train Acc: 37.66%\n",
            "Epoch [3/3] Loss: 43.695 | Train Acc: 38.35%\n",
            "Epoch [3/3] Loss: 47.725 | Train Acc: 38.15%\n",
            "Epoch [3/3] Loss: 51.536 | Train Acc: 38.46%\n",
            "Epoch [3/3] Loss: 55.525 | Train Acc: 38.39%\n",
            "Epoch [3/3] Loss: 59.359 | Train Acc: 38.54%\n",
            "Epoch [3/3] Loss: 63.536 | Train Acc: 38.77%\n",
            "Epoch [3/3] Loss: 67.575 | Train Acc: 38.97%\n",
            "Epoch [3/3] Loss: 71.570 | Train Acc: 38.45%\n",
            "Epoch [3/3] Loss: 75.619 | Train Acc: 38.49%\n",
            "Epoch [3/3] Loss: 79.470 | Train Acc: 38.75%\n",
            "Epoch [3/3] Loss: 83.458 | Train Acc: 38.54%\n",
            "Epoch [3/3] Loss: 87.714 | Train Acc: 38.42%\n",
            "Epoch [3/3] Loss: 91.712 | Train Acc: 38.32%\n",
            "Epoch [3/3] Loss: 95.799 | Train Acc: 38.09%\n",
            "Epoch [3/3] Loss: 99.619 | Train Acc: 38.06%\n",
            "Epoch [3/3] Loss: 103.480 | Train Acc: 38.10%\n",
            "Epoch [3/3] Loss: 107.346 | Train Acc: 38.19%\n",
            "Epoch [3/3] Loss: 111.424 | Train Acc: 38.06%\n",
            "Epoch [3/3] Loss: 115.419 | Train Acc: 38.15%\n",
            "Epoch [3/3] Loss: 119.226 | Train Acc: 38.07%\n",
            "Epoch [3/3] Loss: 123.065 | Train Acc: 38.10%\n",
            "Epoch [3/3] Loss: 127.394 | Train Acc: 37.79%\n",
            "Epoch [3/3] Loss: 131.574 | Train Acc: 37.59%\n",
            "Epoch [3/3] Loss: 135.682 | Train Acc: 37.55%\n",
            "Epoch [3/3] Loss: 139.714 | Train Acc: 37.63%\n",
            "Epoch [3/3] Loss: 143.705 | Train Acc: 37.67%\n",
            "Epoch [3/3] Loss: 147.822 | Train Acc: 37.50%\n",
            "Epoch [3/3] Loss: 151.619 | Train Acc: 37.71%\n",
            "Epoch [3/3] Loss: 155.662 | Train Acc: 37.74%\n",
            "Epoch [3/3] Loss: 159.597 | Train Acc: 37.81%\n",
            "Epoch [3/3] Loss: 163.959 | Train Acc: 37.46%\n",
            "Epoch [3/3] Loss: 168.121 | Train Acc: 37.20%\n",
            "Epoch [3/3] Loss: 172.301 | Train Acc: 36.92%\n",
            "Epoch [3/3] Loss: 176.198 | Train Acc: 36.97%\n",
            "Epoch [3/3] Loss: 180.202 | Train Acc: 36.84%\n",
            "Epoch [3/3] Loss: 184.232 | Train Acc: 36.75%\n",
            "Epoch [3/3] Loss: 188.185 | Train Acc: 36.80%\n",
            "Epoch [3/3] Loss: 192.354 | Train Acc: 36.69%\n",
            "Epoch [3/3] Loss: 196.334 | Train Acc: 36.77%\n",
            "Epoch [3/3] Loss: 200.364 | Train Acc: 36.66%\n",
            "Epoch [3/3] Loss: 204.061 | Train Acc: 36.92%\n",
            "Epoch [3/3] Loss: 208.107 | Train Acc: 36.90%\n",
            "Epoch [3/3] Loss: 211.982 | Train Acc: 36.94%\n",
            "Epoch [3/3] Loss: 215.846 | Train Acc: 36.98%\n",
            "Epoch [3/3] Loss: 219.846 | Train Acc: 36.99%\n",
            "Epoch [3/3] Loss: 224.224 | Train Acc: 36.64%\n",
            "Epoch [3/3] Loss: 228.320 | Train Acc: 36.65%\n",
            "Epoch [3/3] Loss: 232.251 | Train Acc: 36.66%\n",
            "Epoch [3/3] Loss: 236.212 | Train Acc: 36.68%\n",
            "Epoch [3/3] Loss: 240.103 | Train Acc: 36.67%\n",
            "Epoch [3/3] Loss: 244.074 | Train Acc: 36.68%\n",
            "Epoch [3/3] Loss: 248.004 | Train Acc: 36.74%\n",
            "Epoch [3/3] Loss: 252.012 | Train Acc: 36.63%\n",
            "Epoch [3/3] Loss: 256.307 | Train Acc: 36.45%\n",
            "Epoch [3/3] Loss: 260.174 | Train Acc: 36.42%\n",
            "Epoch [3/3] Loss: 264.378 | Train Acc: 36.22%\n",
            "Epoch [3/3] Loss: 268.366 | Train Acc: 36.22%\n",
            "Epoch [3/3] Loss: 272.211 | Train Acc: 36.31%\n",
            "Epoch [3/3] Loss: 276.070 | Train Acc: 36.37%\n",
            "Epoch [3/3] Loss: 280.141 | Train Acc: 36.34%\n",
            "Epoch [3/3] Loss: 284.378 | Train Acc: 36.31%\n",
            "Epoch [3/3] Loss: 288.511 | Train Acc: 36.22%\n",
            "Epoch [3/3] Loss: 292.523 | Train Acc: 36.22%\n",
            "Epoch [3/3] Loss: 296.526 | Train Acc: 36.32%\n",
            "Epoch [3/3] Loss: 300.480 | Train Acc: 36.31%\n",
            "Epoch [3/3] Loss: 304.645 | Train Acc: 36.08%\n",
            "Epoch [3/3] Loss: 308.678 | Train Acc: 36.06%\n",
            "Epoch [3/3] Loss: 312.601 | Train Acc: 36.12%\n",
            "Epoch [3/3] Loss: 316.193 | Train Acc: 36.25%\n",
            "Epoch [3/3] Loss: 320.292 | Train Acc: 36.23%\n",
            "Epoch [3/3] Loss: 324.284 | Train Acc: 36.28%\n",
            "Epoch [3/3] Loss: 327.867 | Train Acc: 36.41%\n",
            "Epoch [3/3] Loss: 331.649 | Train Acc: 36.52%\n",
            "Epoch [3/3] Loss: 335.496 | Train Acc: 36.53%\n",
            "Epoch [3/3] Loss: 339.156 | Train Acc: 36.71%\n",
            "Epoch [3/3] Loss: 343.000 | Train Acc: 36.77%\n",
            "Epoch [3/3] Loss: 346.853 | Train Acc: 36.84%\n",
            "Epoch [3/3] Loss: 350.754 | Train Acc: 36.86%\n",
            "Epoch [3/3] Loss: 354.612 | Train Acc: 36.87%\n",
            "Epoch [3/3] Loss: 358.218 | Train Acc: 37.03%\n",
            "Epoch [3/3] Loss: 362.290 | Train Acc: 36.97%\n",
            "Epoch [3/3] Loss: 366.502 | Train Acc: 36.82%\n",
            "Epoch [3/3] Loss: 370.322 | Train Acc: 36.88%\n",
            "Epoch [3/3] Loss: 374.156 | Train Acc: 36.90%\n",
            "Epoch [3/3] Loss: 378.057 | Train Acc: 36.92%\n",
            "Epoch [3/3] Loss: 382.039 | Train Acc: 36.93%\n",
            "Epoch [3/3] Loss: 386.201 | Train Acc: 36.86%\n",
            "Epoch [3/3] Loss: 389.985 | Train Acc: 36.96%\n",
            "Epoch [3/3] Loss: 393.821 | Train Acc: 37.04%\n",
            "Epoch [3/3] Loss: 397.658 | Train Acc: 37.05%\n",
            "Epoch [3/3] Loss: 401.762 | Train Acc: 36.97%\n",
            "Epoch [3/3] Loss: 405.461 | Train Acc: 37.06%\n",
            "Epoch [3/3] Loss: 409.328 | Train Acc: 37.08%\n",
            "Epoch [3/3] Loss: 412.877 | Train Acc: 37.21%\n",
            "Epoch [3/3] Loss: 416.593 | Train Acc: 37.23%\n",
            "Epoch [3/3] Loss: 420.259 | Train Acc: 37.34%\n",
            "Epoch [3/3] Loss: 423.983 | Train Acc: 37.35%\n",
            "Epoch [3/3] Loss: 428.035 | Train Acc: 37.31%\n",
            "Epoch [3/3] Loss: 431.564 | Train Acc: 37.40%\n",
            "Epoch [3/3] Loss: 435.569 | Train Acc: 37.41%\n",
            "Epoch [3/3] Loss: 439.507 | Train Acc: 37.44%\n",
            "Epoch [3/3] Loss: 443.379 | Train Acc: 37.43%\n",
            "Epoch [3/3] Loss: 447.214 | Train Acc: 37.46%\n",
            "Epoch [3/3] Loss: 451.362 | Train Acc: 37.42%\n",
            "Epoch [3/3] Loss: 455.326 | Train Acc: 37.36%\n",
            "Epoch [3/3] Loss: 459.078 | Train Acc: 37.45%\n",
            "Epoch [3/3] Loss: 463.010 | Train Acc: 37.43%\n",
            "Epoch [3/3] Loss: 466.993 | Train Acc: 37.38%\n",
            "Epoch [3/3] Loss: 471.141 | Train Acc: 37.29%\n",
            "Epoch [3/3] Loss: 475.227 | Train Acc: 37.17%\n",
            "Epoch [3/3] Loss: 478.996 | Train Acc: 37.20%\n",
            "Epoch [3/3] Loss: 482.980 | Train Acc: 37.17%\n",
            "Epoch [3/3] Loss: 486.922 | Train Acc: 37.13%\n",
            "Epoch [3/3] Loss: 490.704 | Train Acc: 37.16%\n",
            "Epoch [3/3] Loss: 494.476 | Train Acc: 37.19%\n",
            "Epoch [3/3] Loss: 498.378 | Train Acc: 37.18%\n",
            "Epoch [3/3] Loss: 502.426 | Train Acc: 37.14%\n",
            "Epoch [3/3] Loss: 506.175 | Train Acc: 37.15%\n",
            "Epoch [3/3] Loss: 510.029 | Train Acc: 37.12%\n",
            "Epoch [3/3] Loss: 513.949 | Train Acc: 37.15%\n",
            "Epoch [3/3] Loss: 517.753 | Train Acc: 37.13%\n",
            "Epoch [3/3] Loss: 521.737 | Train Acc: 37.12%\n",
            "Epoch [3/3] Loss: 525.591 | Train Acc: 37.15%\n",
            "Epoch [3/3] Loss: 529.248 | Train Acc: 37.20%\n",
            "Epoch [3/3] Loss: 532.828 | Train Acc: 37.21%\n",
            "Epoch [3/3] Loss: 536.675 | Train Acc: 37.19%\n",
            "Epoch [3/3] Loss: 540.565 | Train Acc: 37.19%\n",
            "Epoch [3/3] Loss: 544.563 | Train Acc: 37.13%\n",
            "Epoch [3/3] Loss: 548.380 | Train Acc: 37.15%\n",
            "Epoch [3/3] Loss: 552.232 | Train Acc: 37.17%\n",
            "Epoch [3/3] Loss: 556.170 | Train Acc: 37.11%\n",
            "Epoch [3/3] Loss: 560.047 | Train Acc: 37.15%\n",
            "Epoch [3/3] Loss: 563.950 | Train Acc: 37.15%\n",
            "Epoch [3/3] Loss: 567.817 | Train Acc: 37.15%\n",
            "Epoch [3/3] Loss: 571.567 | Train Acc: 37.13%\n",
            "Epoch [3/3] Loss: 575.237 | Train Acc: 37.15%\n",
            "Epoch [3/3] Loss: 578.889 | Train Acc: 37.16%\n",
            "Epoch [3/3] Loss: 582.945 | Train Acc: 37.10%\n",
            "Epoch [3/3] Loss: 586.772 | Train Acc: 37.10%\n",
            "Epoch [3/3] Loss: 590.504 | Train Acc: 37.17%\n",
            "Epoch [3/3] Loss: 594.472 | Train Acc: 37.14%\n",
            "Epoch [3/3] Loss: 598.296 | Train Acc: 37.18%\n",
            "Epoch [3/3] Loss: 602.200 | Train Acc: 37.20%\n",
            "Epoch [3/3] Loss: 606.054 | Train Acc: 37.22%\n",
            "Epoch [3/3] Loss: 609.903 | Train Acc: 37.25%\n",
            "Epoch [3/3] Loss: 613.605 | Train Acc: 37.22%\n",
            "Epoch [3/3] Loss: 617.411 | Train Acc: 37.22%\n",
            "Epoch [3/3] Loss: 621.370 | Train Acc: 37.20%\n",
            "Epoch [3/3] Loss: 624.946 | Train Acc: 37.22%\n",
            "Epoch [3/3] Loss: 628.745 | Train Acc: 37.24%\n",
            "Epoch [3/3] Loss: 632.509 | Train Acc: 37.27%\n",
            "Epoch [3/3] Loss: 636.324 | Train Acc: 37.25%\n",
            "Epoch [3/3] Loss: 640.197 | Train Acc: 37.27%\n",
            "Epoch [3/3] Loss: 643.967 | Train Acc: 37.32%\n",
            "Epoch [3/3] Loss: 647.758 | Train Acc: 37.33%\n",
            "Epoch [3/3] Loss: 651.421 | Train Acc: 37.36%\n",
            "Epoch [3/3] Loss: 654.969 | Train Acc: 37.41%\n",
            "Epoch [3/3] Loss: 658.796 | Train Acc: 37.39%\n",
            "Epoch [3/3] Loss: 662.568 | Train Acc: 37.40%\n",
            "Epoch [3/3] Loss: 666.394 | Train Acc: 37.34%\n",
            "Epoch [3/3] Loss: 670.170 | Train Acc: 37.34%\n",
            "Epoch [3/3] Loss: 674.075 | Train Acc: 37.34%\n",
            "Epoch [3/3] Loss: 677.710 | Train Acc: 37.35%\n",
            "Epoch [3/3] Loss: 681.726 | Train Acc: 37.32%\n",
            "Epoch [3/3] Loss: 685.220 | Train Acc: 37.34%\n",
            "Epoch [3/3] Loss: 688.978 | Train Acc: 37.32%\n",
            "Epoch [3/3] Loss: 692.774 | Train Acc: 37.31%\n",
            "Epoch [3/3] Loss: 696.904 | Train Acc: 37.25%\n",
            "Epoch [3/3] Loss: 700.636 | Train Acc: 37.27%\n",
            "Epoch [3/3] Loss: 704.043 | Train Acc: 37.33%\n",
            "Epoch [3/3] Loss: 708.067 | Train Acc: 37.30%\n",
            "Epoch [3/3] Loss: 711.954 | Train Acc: 37.28%\n",
            "Epoch [3/3] Loss: 715.960 | Train Acc: 37.27%\n",
            "Epoch [3/3] Loss: 719.530 | Train Acc: 37.32%\n",
            "Epoch [3/3] Loss: 723.099 | Train Acc: 37.36%\n",
            "Epoch [3/3] Loss: 726.664 | Train Acc: 37.38%\n",
            "Epoch [3/3] Loss: 730.024 | Train Acc: 37.42%\n",
            "Epoch [3/3] Loss: 734.216 | Train Acc: 37.38%\n",
            "Epoch [3/3] Loss: 737.945 | Train Acc: 37.41%\n",
            "Epoch [3/3] Loss: 741.576 | Train Acc: 37.41%\n",
            "Epoch [3/3] Loss: 745.237 | Train Acc: 37.46%\n",
            "Epoch [3/3] Loss: 748.798 | Train Acc: 37.52%\n",
            "Epoch [3/3] Loss: 752.387 | Train Acc: 37.56%\n",
            "Epoch [3/3] Loss: 755.848 | Train Acc: 37.60%\n",
            "Epoch [3/3] Loss: 759.590 | Train Acc: 37.59%\n",
            "Epoch [3/3] Loss: 763.309 | Train Acc: 37.58%\n",
            "Epoch [3/3] Loss: 767.424 | Train Acc: 37.53%\n",
            "Epoch [3/3] Loss: 771.264 | Train Acc: 37.56%\n",
            "Epoch [3/3] Loss: 774.879 | Train Acc: 37.58%\n",
            "Epoch [3/3] Loss: 778.771 | Train Acc: 37.55%\n",
            "Epoch [3/3] Loss: 782.280 | Train Acc: 37.59%\n",
            "Epoch [3/3] Loss: 785.721 | Train Acc: 37.62%\n",
            "Epoch [3/3] Loss: 788.974 | Train Acc: 37.68%\n",
            "Epoch [3/3] Loss: 792.574 | Train Acc: 37.73%\n",
            "Epoch [3/3] Loss: 796.562 | Train Acc: 37.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **image to embeddings**"
      ],
      "metadata": {
        "id": "vcyKfroFosQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet"
      ],
      "metadata": {
        "id": "ypM6xKQQozbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        output = model(images)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "val_acc = 100 * correct / total\n",
        "print(\"Validation Accuracy:\", val_acc)\n"
      ],
      "metadata": {
        "id": "FMGe4orqj2rF",
        "outputId": "50aaafb6-f051-44e9-e13d-0be0bebce479",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(\n",
        "    model.state_dict(),\n",
        "    \"/content/drive/MyDrive/face_proj/phase1_casia_magf.pth\"\n",
        ")\n",
        "print(\"Model saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoA2YRwTkBSe",
        "outputId": "d260bd3f-0441-4461-e4d0-da6ef5125fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.classes[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA2jWjgKZLQ3",
        "outputId": "65ff73b8-502a-4a56-daed-5534b5647c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0000045', '0000099', '0000100', '0000102', '0000103', '0000105', '0000107', '0000108', '0000114', '0000117']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "base_model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Remove classifier entirely\n",
        "base_model.fc = nn.Identity()\n",
        "\n",
        "base_model = base_model.to(device)\n",
        "base_model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W410KYz7Zd8d",
        "outputId": "67443db7-ee64-4b8d-9039-0fabab4ebee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Identity()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, lbls in val_loader:\n",
        "        images = images.to(device)\n",
        "        feats = base_model(images)   # [B, 512]\n",
        "\n",
        "        embeddings.append(feats.cpu())\n",
        "        labels.append(lbls)\n",
        "\n",
        "embeddings = torch.cat(embeddings).numpy()\n",
        "labels = torch.cat(labels).numpy()\n",
        "\n",
        "print(\"Embeddings shape:\", embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeYQHCi_Zm4L",
        "outputId": "b707a384-018f-425b-f40c-dce1de25cfe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (2551, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Map identity â†’ embedding indices\n",
        "id_to_indices = defaultdict(list)\n",
        "for idx, lbl in enumerate(labels):\n",
        "    id_to_indices[lbl].append(idx)\n",
        "\n",
        "pairs = []\n",
        "pair_labels = []\n",
        "\n",
        "# Positive pairs (same identity)\n",
        "for lbl, idxs in id_to_indices.items():\n",
        "    if len(idxs) >= 2:\n",
        "        i1, i2 = random.sample(idxs, 2)\n",
        "        pairs.append((i1, i2))\n",
        "        pair_labels.append(1)\n",
        "\n",
        "# Negative pairs (different identities)\n",
        "all_labels = list(id_to_indices.keys())\n",
        "\n",
        "for _ in range(len(pairs)):\n",
        "    l1, l2 = random.sample(all_labels, 2)\n",
        "    i1 = random.choice(id_to_indices[l1])\n",
        "    i2 = random.choice(id_to_indices[l2])\n",
        "    pairs.append((i1, i2))\n",
        "    pair_labels.append(0)\n",
        "\n",
        "pairs = np.array(pairs)\n",
        "pair_labels = np.array(pair_labels)\n",
        "\n",
        "print(\"Total pairs:\", len(pairs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB_AJMJPaG6C",
        "outputId": "57292700-bab6-4c15-a58e-8191adf6122a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pairs: 140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "scores = []\n",
        "\n",
        "for i1, i2 in pairs:\n",
        "    sim = cosine_similarity(\n",
        "        embeddings[i1].reshape(1, -1),\n",
        "        embeddings[i2].reshape(1, -1)\n",
        "    )[0][0]\n",
        "    scores.append(sim)\n",
        "\n",
        "scores = np.array(scores)\n"
      ],
      "metadata": {
        "id": "RolhjAQgb2vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "same_scores = scores[pair_labels == 1]\n",
        "diff_scores = scores[pair_labels == 0]\n",
        "\n",
        "print(\"Same-person mean similarity:\", same_scores.mean())\n",
        "print(\"Different-person mean similarity:\", diff_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWyzwcc-dG5v",
        "outputId": "3c11f647-cfbf-48cc-d77d-42a60d6df684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Same-person mean similarity: 0.8047906\n",
            "Different-person mean similarity: 0.7520156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##EER\n",
        "from sklearn.metrics import roc_curve\n",
        "import numpy as np\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(pair_labels, scores, pos_label=1)\n",
        "fnr = 1 - tpr\n",
        "\n",
        "eer_idx = np.nanargmin(np.abs(fpr - fnr))\n",
        "eer = fpr[eer_idx]\n",
        "\n",
        "print(\"EER:\", eer) #shows how many decisions are wrong\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgvDMUN_nrBz",
        "outputId": "9f8ab937-1970-499f-eb52-190169324665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EER: 0.37142857142857144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet+ArcFace Loss function"
      ],
      "metadata": {
        "id": "d9TdSqqSo5Rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface\n"
      ],
      "metadata": {
        "id": "5MIlHvtHcN2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class ArcMarginProduct(nn.Module):\n",
        "    def __init__(self, in_features, out_features, s=30.0, m=0.50):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "\n",
        "    def forward(self, x, label):\n",
        "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
        "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "\n",
        "        one_hot = torch.zeros(cosine.size(), device=x.device)\n",
        "        one_hot.scatter_(1, label.view(-1, 1), 1.0)\n",
        "\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "P4o_z7SRd1Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "num_classes = len(dataset.classes)\n",
        "\n",
        "backbone = models.resnet18(pretrained=True)\n",
        "backbone.fc = nn.Identity()\n",
        "backbone = backbone.to(device)\n",
        "\n",
        "arcface = ArcMarginProduct(\n",
        "    in_features=512,\n",
        "    out_features=num_classes,\n",
        "    s=30.0,\n",
        "    m=0.5\n",
        ").to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujBXUkEIeAVf",
        "outputId": "20b0a706-0432-429b-8e73-41a15314a74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(backbone.parameters()) + list(arcface.parameters()),\n",
        "    lr=1e-4\n",
        ")\n"
      ],
      "metadata": {
        "id": "9n69hoSqiBfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(15):   # 3â€“5 epochs is enough for now\n",
        "    backbone.train()\n",
        "    arcface.train()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        embeddings = backbone(images)\n",
        "        logits = arcface(embeddings, labels)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}] Loss: {total_loss:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "lvINgBXbiGFT",
        "outputId": "4fcb7530-4413-4f22-9c81-91cb3aa92a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3066143442.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoch+1}] Loss: {total_loss:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backbone.eval()\n",
        "\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, lbls in val_loader:\n",
        "        images = images.to(device)\n",
        "        feats = backbone(images)\n",
        "        embeddings.append(feats.cpu())\n",
        "        labels.append(lbls)\n",
        "\n",
        "embeddings = torch.cat(embeddings).numpy()\n",
        "labels = torch.cat(labels).numpy()\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "embeddings = normalize(embeddings)\n"
      ],
      "metadata": {
        "id": "HqlIEGUFiSxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "id_to_indices = defaultdict(list)\n",
        "for idx, lbl in enumerate(labels):\n",
        "    id_to_indices[lbl].append(idx)\n",
        "\n",
        "pairs = []\n",
        "pair_labels = []   # 1 = same person, 0 = different\n",
        "\n",
        "# Positive (same identity)\n",
        "for lbl, idxs in id_to_indices.items():\n",
        "    if len(idxs) >= 2:\n",
        "        i1, i2 = random.sample(idxs, 2)\n",
        "        pairs.append((i1, i2))\n",
        "        pair_labels.append(1)\n",
        "\n",
        "# Negative (different identity)\n",
        "all_labels = list(id_to_indices.keys())\n",
        "\n",
        "for _ in range(len(pairs)):\n",
        "    l1, l2 = random.sample(all_labels, 2)\n",
        "    i1 = random.choice(id_to_indices[l1])\n",
        "    i2 = random.choice(id_to_indices[l2])\n",
        "    pairs.append((i1, i2))\n",
        "    pair_labels.append(0)\n",
        "\n",
        "pairs = np.array(pairs)\n",
        "pair_labels = np.array(pair_labels)\n",
        "\n",
        "print(\"Total verification pairs:\", len(pairs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fulftf_i1nq",
        "outputId": "e191d595-a35d-4126-c3d8-ab3d0528c864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total verification pairs: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "scores = []\n",
        "\n",
        "for i1, i2 in pairs:\n",
        "    sim = cosine_similarity(\n",
        "        embeddings[i1].reshape(1, -1),\n",
        "        embeddings[i2].reshape(1, -1)\n",
        "    )[0][0]\n",
        "    scores.append(sim)\n",
        "\n",
        "scores = np.array(scores)\n"
      ],
      "metadata": {
        "id": "efnGyEpOiW4D",
        "outputId": "0939cbaa-382e-47e2-822b-24b991fc59e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 32 is out of bounds for dimension 0 with size 32",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-392238356.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     sim = cosine_similarity(\n\u001b[1;32m      7\u001b[0m         \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     )[0][0]\n\u001b[1;32m     10\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 32 is out of bounds for dimension 0 with size 32"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(pair_labels, scores, pos_label=1)\n",
        "fnr = 1 - tpr\n"
      ],
      "metadata": {
        "id": "0LpGVnpVi8l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "eer_index = np.nanargmin(np.abs(fpr - fnr))\n",
        "eer = fpr[eer_index]\n",
        "\n",
        "print(\"EER:\", eer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IgobHadi_Zu",
        "outputId": "4221bbb3-0693-448a-c66f-078c5f28a2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EER: 0.45714285714285713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet+MagFace"
      ],
      "metadata": {
        "id": "URZ-MyXDmGoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class MagFace(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        s=30.0,\n",
        "        m_min=0.45,\n",
        "        m_max=0.8,\n",
        "        l_a=10,\n",
        "        u_a=110\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s\n",
        "\n",
        "        self.m_min = m_min\n",
        "        self.m_max = m_max\n",
        "        self.l_a = l_a\n",
        "        self.u_a = u_a\n",
        "\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        # embedding norm = quality\n",
        "        norm = torch.norm(embeddings, dim=1, keepdim=True).clamp(self.l_a, self.u_a)\n",
        "\n",
        "        # adaptive margin\n",
        "        margin = (\n",
        "            self.m_min +\n",
        "            (self.m_max - self.m_min) *\n",
        "            (norm - self.l_a) / (self.u_a - self.l_a)\n",
        "        )\n",
        "\n",
        "        cosine = F.linear(F.normalize(embeddings), F.normalize(self.weight))\n",
        "        sine = torch.sqrt(1.0 - cosine ** 2 + 1e-6)\n",
        "        phi = cosine * torch.cos(margin) - sine * torch.sin(margin)\n",
        "\n",
        "        one_hot = torch.zeros_like(cosine)\n",
        "        one_hot.scatter_(1, labels.view(-1, 1), 1.0)\n",
        "\n",
        "        output = one_hot * phi + (1.0 - one_hot) * cosine\n",
        "        output *= self.s\n",
        "\n",
        "        return output, norm\n"
      ],
      "metadata": {
        "id": "vEhfHoOElyaO"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace MagFace temporarily\n",
        "classifier = nn.Linear(512, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(backbone.parameters()) + list(classifier.parameters()),\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "for epoch in range(3):\n",
        "    backbone.train()\n",
        "    classifier.train()\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        embeddings = backbone(images)\n",
        "        logits = classifier(embeddings)\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "sJoAuY5iufvh"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "magface = MagFace(512, num_classes).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(backbone.parameters()) + list(magface.parameters()),\n",
        "    lr=1e-4\n",
        ")\n"
      ],
      "metadata": {
        "id": "NNtVJDBwukJU"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "# num_classes = len(dataset.classes)\n",
        "\n",
        "# backbone = models.resnet18(pretrained=True)\n",
        "# backbone.fc = nn.Identity()\n",
        "# backbone = backbone.to(device)\n",
        "\n",
        "\n",
        "magface = MagFace(\n",
        "    in_features=512,\n",
        "    out_features=num_classes\n",
        ")\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "magface = magface.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(backbone.parameters()) + list(magface.parameters()),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-4\n",
        ")\n"
      ],
      "metadata": {
        "id": "0_6dsLhBR9CK"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    print(\"Images:\", images.device)\n",
        "    print(\"Model :\", next(backbone.parameters()).device)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "B3_SakhXi6OG",
        "outputId": "289310a5-0d9f-4041-ab95-95ec97734727",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images: cuda:0\n",
            "Model : cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(15):\n",
        "    backbone.train()\n",
        "    magface.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {i}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        embeddings = backbone(images)\n",
        "        logits, norms = magface(embeddings, labels)\n",
        "\n",
        "        loss_id = ce_loss(logits, labels)\n",
        "        loss_reg = torch.mean((norms - magface.l_a) ** 2)\n",
        "\n",
        "        loss = loss_id + 0.01 * loss_reg\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.3f}\")\n"
      ],
      "metadata": {
        "id": "n_KBVXQyRREZ",
        "outputId": "2f4a1dc8-dadd-4571-988b-8bbf3de042ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 0\n",
            "Epoch 1, Batch 100\n",
            "Epoch 1, Batch 200\n",
            "Epoch 1 | Loss: 3702.549\n",
            "Epoch 2, Batch 0\n",
            "Epoch 2, Batch 100\n",
            "Epoch 2, Batch 200\n",
            "Epoch 2 | Loss: 2193.959\n",
            "Epoch 3, Batch 0\n",
            "Epoch 3, Batch 100\n",
            "Epoch 3, Batch 200\n",
            "Epoch 3 | Loss: 1050.088\n",
            "Epoch 4, Batch 0\n",
            "Epoch 4, Batch 100\n",
            "Epoch 4, Batch 200\n",
            "Epoch 4 | Loss: 410.527\n",
            "Epoch 5, Batch 0\n",
            "Epoch 5, Batch 100\n",
            "Epoch 5, Batch 200\n",
            "Epoch 5 | Loss: 172.633\n",
            "Epoch 6, Batch 0\n",
            "Epoch 6, Batch 100\n",
            "Epoch 6, Batch 200\n",
            "Epoch 6 | Loss: 75.435\n",
            "Epoch 7, Batch 0\n",
            "Epoch 7, Batch 100\n",
            "Epoch 7, Batch 200\n",
            "Epoch 7 | Loss: 40.855\n",
            "Epoch 8, Batch 0\n",
            "Epoch 8, Batch 100\n",
            "Epoch 8, Batch 200\n",
            "Epoch 8 | Loss: 27.271\n",
            "Epoch 9, Batch 0\n",
            "Epoch 9, Batch 100\n",
            "Epoch 9, Batch 200\n",
            "Epoch 9 | Loss: 25.229\n",
            "Epoch 10, Batch 0\n",
            "Epoch 10, Batch 100\n",
            "Epoch 10, Batch 200\n",
            "Epoch 10 | Loss: 20.467\n",
            "Epoch 11, Batch 0\n",
            "Epoch 11, Batch 100\n",
            "Epoch 11, Batch 200\n",
            "Epoch 11 | Loss: 14.239\n",
            "Epoch 12, Batch 0\n",
            "Epoch 12, Batch 100\n",
            "Epoch 12, Batch 200\n",
            "Epoch 12 | Loss: 28.933\n",
            "Epoch 13, Batch 0\n",
            "Epoch 13, Batch 100\n",
            "Epoch 13, Batch 200\n",
            "Epoch 13 | Loss: 102.457\n",
            "Epoch 14, Batch 0\n",
            "Epoch 14, Batch 100\n",
            "Epoch 14, Batch 200\n",
            "Epoch 14 | Loss: 79.364\n",
            "Epoch 15, Batch 0\n",
            "Epoch 15, Batch 100\n",
            "Epoch 15, Batch 200\n",
            "Epoch 15 | Loss: 34.077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset_fd = FaceDetectDataset(val_dataset, mtcnn)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "val_loader_fd = DataLoader(\n",
        "    val_dataset_fd,\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "hp6C4eQ46Rtk"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "backbone.eval()\n",
        "with torch.no_grad():\n",
        "    for imgs, lbls in val_loader_fd:\n",
        "        imgs = imgs.to(device)\n",
        "        feats = backbone(imgs)\n",
        "        embeddings.append(feats.cpu())\n",
        "        labels.append(lbls)\n",
        "\n",
        "import torch\n",
        "embeddings = torch.cat(embeddings).numpy()\n",
        "labels = torch.cat(labels).numpy()\n",
        "\n",
        "print(\"Embeddings shape:\", embeddings.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "# normalize embeddings\n",
        "embeddings = normalize(embeddings, axis=1)"
      ],
      "metadata": {
        "id": "dhFy0l_ySO19",
        "outputId": "b867d472-ba4f-4719-9f69-94338e00ffce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (3327, 512)\n",
            "Labels shape: (3327,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "print(\"Val dataset size:\", len(val_dataset))\n",
        "\n",
        "val_labels = []\n",
        "for _, lbl in val_dataset:\n",
        "    val_labels.append(lbl)\n",
        "\n",
        "label_counts = Counter(val_labels)\n",
        "\n",
        "print(\"Number of identities in val:\", len(label_counts))\n",
        "print(\"Images per identity (val):\", label_counts)\n",
        "print(\"Identities with >=2 images:\",\n",
        "      sum(1 for v in label_counts.values() if v >= 2))\n"
      ],
      "metadata": {
        "id": "YePdYjRwtQ1Q",
        "outputId": "57145b8d-684d-40d3-e1b3-e4b9798a24c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val dataset size: 3327\n",
            "Number of identities in val: 140\n",
            "Images per identity (val): Counter({332: 25, 578: 25, 416: 25, 315: 25, 165: 25, 537: 25, 195: 25, 242: 25, 461: 25, 145: 25, 386: 25, 629: 25, 100: 25, 475: 25, 12: 25, 547: 25, 343: 25, 688: 25, 162: 25, 417: 25, 128: 25, 428: 25, 39: 25, 1: 25, 496: 25, 413: 25, 600: 25, 649: 25, 391: 25, 308: 25, 426: 25, 561: 25, 319: 25, 167: 25, 8: 25, 570: 25, 271: 25, 61: 25, 68: 25, 133: 25, 51: 25, 616: 25, 151: 25, 587: 25, 104: 25, 349: 25, 571: 25, 660: 25, 405: 25, 136: 25, 573: 25, 697: 25, 139: 25, 103: 25, 144: 25, 504: 25, 153: 25, 193: 25, 695: 25, 92: 25, 609: 25, 467: 25, 203: 25, 589: 25, 265: 25, 377: 25, 533: 25, 412: 25, 3: 25, 432: 25, 18: 25, 344: 25, 97: 25, 38: 25, 550: 25, 314: 25, 36: 25, 596: 25, 311: 25, 54: 25, 218: 25, 278: 25, 197: 25, 142: 25, 399: 25, 648: 25, 185: 25, 464: 25, 522: 25, 598: 25, 469: 25, 350: 25, 65: 25, 287: 25, 66: 25, 325: 25, 402: 25, 289: 25, 397: 25, 567: 25, 182: 25, 389: 25, 529: 25, 530: 25, 610: 25, 474: 25, 192: 25, 177: 25, 485: 25, 556: 25, 44: 25, 536: 25, 565: 25, 157: 25, 372: 25, 225: 25, 620: 24, 574: 24, 515: 23, 282: 23, 499: 22, 619: 21, 369: 21, 560: 21, 441: 20, 80: 20, 643: 19, 559: 18, 608: 17, 415: 16, 55: 16, 160: 16, 576: 16, 468: 16, 329: 15, 64: 14, 113: 14, 300: 12, 400: 11, 662: 8})\n",
            "Identities with >=2 images: 140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WmFjCTeZuM2T"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "id_to_indices = defaultdict(list)\n",
        "for idx, lbl in enumerate(labels):\n",
        "    id_to_indices[lbl].append(idx)\n",
        "\n",
        "pairs = []\n",
        "pair_labels = []\n",
        "\n",
        "# --- Positive pairs (deterministic) ---\n",
        "for lbl, idxs in id_to_indices.items():\n",
        "    if len(idxs) >= 2:\n",
        "        for i in range(len(idxs) - 1):\n",
        "            pairs.append((idxs[i], idxs[i+1]))\n",
        "            pair_labels.append(1)\n",
        "\n",
        "# --- Negative pairs (deterministic, balanced) ---\n",
        "all_labels = sorted(id_to_indices.keys())\n",
        "\n",
        "# neg_pairs = []\n",
        "# for i in range(len(all_labels)):\n",
        "#     for j in range(i+1, len(all_labels)):\n",
        "#         neg_pairs.append((\n",
        "#             id_to_indices[all_labels[i]][0],\n",
        "#             id_to_indices[all_labels[j]][0]\n",
        "#         ))\n",
        "neg_pairs = []\n",
        "while len(neg_pairs) < len(pairs):\n",
        "    id1, id2 = random.sample(all_labels, 2)\n",
        "    i1 = random.choice(id_to_indices[id1])\n",
        "    i2 = random.choice(id_to_indices[id2])\n",
        "    neg_pairs.append((i1, i2))\n",
        "\n",
        "# Balance positives and negatives\n",
        "neg_pairs = neg_pairs[:len(pairs)]\n",
        "\n",
        "pairs.extend(neg_pairs)\n",
        "pair_labels.extend([0] * len(neg_pairs))\n",
        "\n",
        "pairs = np.array(pairs)\n",
        "pair_labels = np.array(pair_labels)\n",
        "\n",
        "print(\"Total pairs:\", len(pairs))\n",
        "print(\"Label distribution:\", np.unique(pair_labels, return_counts=True))\n",
        "\n"
      ],
      "metadata": {
        "id": "KW0zZGI1v4YC",
        "outputId": "d928b070-8845-42ca-e1af-816bbccf4104",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pairs: 6374\n",
            "Label distribution: (array([0, 1]), array([3187, 3187]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "# import numpy as np\n",
        "\n",
        "# scores = []\n",
        "\n",
        "# for i1, i2 in pairs:\n",
        "#     scores.append(\n",
        "#         cosine_similarity(\n",
        "#             embeddings[i1].reshape(1,-1),\n",
        "#             embeddings[i2].reshape(1,-1)\n",
        "#         )[0][0]\n",
        "#     )\n",
        "\n",
        "# scores = np.array(scores)\n",
        "# print(\"Scores length:\", len(scores))\n"
      ],
      "metadata": {
        "id": "lGx79ZJ8Zg_7"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"pair_labels unique:\", np.unique(pair_labels, return_counts=True))\n",
        "print(\"scores stats:\")\n",
        "print(\"  min:\", np.min(scores))\n",
        "print(\"  max:\", np.max(scores))\n",
        "print(\"  mean:\", np.mean(scores))\n",
        "print(\"Any NaN in scores?\", np.isnan(scores).any())\n"
      ],
      "metadata": {
        "id": "c90Os2nZvb9X",
        "outputId": "47328159-3f28-454a-fd61-4ff6a4bab5a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pair_labels unique: (array([0, 1]), array([3187, 3187]))\n",
            "scores stats:\n",
            "  min: 0.19324577\n",
            "  max: 0.9452292\n",
            "  mean: 0.46255192\n",
            "Any NaN in scores? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import roc_curve\n",
        "import numpy as np\n",
        "\n",
        "scores = []\n",
        "for i1, i2 in pairs:\n",
        "    scores.append(\n",
        "        np.dot(embeddings[i1], embeddings[i2])  # faster cosine\n",
        "    )\n",
        "\n",
        "scores = np.array(scores)\n",
        "pair_labels = np.array(pair_labels)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(pair_labels, scores)\n",
        "fnr = 1 - tpr\n",
        "\n",
        "idx = np.nanargmin(np.abs(fpr - fnr))\n",
        "eer = (fpr[idx] + fnr[idx]) / 2\n",
        "\n",
        "print(\"EER:\", eer)\n",
        "target_far = 0.05\n",
        "far_idx = np.argmin(np.abs(fpr - target_far))\n",
        "frr_at_far = fnr[far_idx]\n",
        "\n",
        "print(\"FRR @ FAR=1%:\", frr_at_far)\n",
        "\n"
      ],
      "metadata": {
        "id": "B2t423A1sa1l",
        "outputId": "752e9347-21ea-4c47-fba8-f878c76509af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EER: 0.4769375588327581\n",
            "FRR @ FAR=1%: 0.9350486350800126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/face_proj\n"
      ],
      "metadata": {
        "id": "TtKH-KI0k4gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Correcteddd\n"
      ],
      "metadata": {
        "id": "ysILDOFI0svG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = dataset.targets\n",
        "id_to_indices = defaultdict(list)\n",
        "\n",
        "for idx, lbl in enumerate(labels):\n",
        "    id_to_indices[lbl].append(idx)\n",
        "\n",
        "ids = list(id_to_indices.keys())\n",
        "random.shuffle(ids)\n",
        "\n",
        "split = int(0.8 * len(ids))\n",
        "train_ids = ids[:split]\n",
        "val_ids = ids[split:]\n",
        "\n",
        "train_idx, val_idx = [], []\n",
        "\n",
        "for i in train_ids:\n",
        "    train_idx.extend(id_to_indices[i])\n",
        "for i in val_ids:\n",
        "    val_idx.extend(id_to_indices[i])\n",
        "\n",
        "train_dataset = Subset(dataset, train_idx)\n",
        "val_dataset   = Subset(dataset, val_idx)\n",
        "\n",
        "print(\"Train images:\", len(train_dataset))\n",
        "print(\"Val images:\", len(val_dataset))\n"
      ],
      "metadata": {
        "id": "RH2BH71B0raE",
        "outputId": "975b9d78-f35a-4583-c939-01ad5632160b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: 14830\n",
            "Val images: 3726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "QIbVMvQK0yRD"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(dataset.classes)\n",
        "\n",
        "backbone = models.resnet18(pretrained=True)\n",
        "backbone.fc = nn.Identity()\n",
        "backbone = backbone.to(device)\n"
      ],
      "metadata": {
        "id": "noELF1re01Bl",
        "outputId": "d76b2ef1-35f2-4f96-cd82-74720d6d7581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4127638429.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1149\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MagFace(nn.Module):\n",
        "    def __init__(self, in_features, out_features,\n",
        "                 s=30.0, m_min=0.45, m_max=0.8,\n",
        "                 l_a=10, u_a=110):\n",
        "        super().__init__()\n",
        "        self.s = s\n",
        "        self.m_min = m_min\n",
        "        self.m_max = m_max\n",
        "        self.l_a = l_a\n",
        "        self.u_a = u_a\n",
        "\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        norms = torch.norm(embeddings, dim=1, keepdim=True)\n",
        "        norms = norms.clamp(self.l_a, self.u_a)\n",
        "\n",
        "        margin = self.m_min + (self.m_max - self.m_min) * \\\n",
        "                 (norms - self.l_a) / (self.u_a - self.l_a)\n",
        "\n",
        "        cosine = F.linear(F.normalize(embeddings),\n",
        "                          F.normalize(self.weight))\n",
        "        sine = torch.sqrt(1.0 - cosine**2 + 1e-6)\n",
        "        phi = cosine * torch.cos(margin) - sine * torch.sin(margin)\n",
        "\n",
        "        one_hot = torch.zeros_like(cosine)\n",
        "        one_hot.scatter_(1, labels.view(-1, 1), 1.0)\n",
        "\n",
        "        logits = (one_hot * phi + (1.0 - one_hot) * cosine) * self.s\n",
        "        return logits, norms\n"
      ],
      "metadata": {
        "id": "OlFksoWD02o8"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(\n",
        "    list(backbone.parameters()) + list(magface.parameters()),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-4\n",
        ")\n"
      ],
      "metadata": {
        "id": "nOocfXcB04uD"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    print(\"Images:\", images.device)\n",
        "    print(\"Model :\", next(backbone.parameters()).device)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "dJJDlhI85h22",
        "outputId": "922a8203-b659-415b-f806-ac94178ee599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2215458956.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Images:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    backbone.train()\n",
        "    magface.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        embeddings = backbone(images)\n",
        "        logits, norms = magface(embeddings, labels)\n",
        "\n",
        "        loss_id = criterion(logits, labels)\n",
        "        loss_reg = torch.mean((norms - magface.l_a) ** 2)\n",
        "\n",
        "        loss = loss_id + 0.01 * loss_reg\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1} | Batch {i} | Loss {loss.item():.3f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1} DONE | Avg loss: {total_loss/len(train_loader):.3f}\")\n"
      ],
      "metadata": {
        "id": "R6SamtSA064k",
        "outputId": "8361ff2f-4ad8-4798-fab2-47104e15ece1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-263798386.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-464808844.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings, labels)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backbone.eval()\n",
        "embeddings, labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, lbls in val_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        feats = F.normalize(backbone(imgs), dim=1)\n",
        "        embeddings.append(feats.cpu())\n",
        "        labels.append(lbls)\n",
        "\n",
        "embeddings = torch.cat(embeddings).numpy()\n",
        "labels = torch.cat(labels).numpy()\n",
        "\n",
        "print(\"Embeddings:\", embeddings.shape)\n"
      ],
      "metadata": {
        "id": "QCqF6Pz009DY",
        "outputId": "ecba66b7-3bd4-4d77-f8d0-71fc84d0dcdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings: (3302, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_indices = defaultdict(list)\n",
        "for i, lbl in enumerate(labels):\n",
        "    id_to_indices[lbl].append(i)\n",
        "\n",
        "pairs, pair_labels = [], []\n",
        "\n",
        "# Positive pairs\n",
        "for idxs in id_to_indices.values():\n",
        "    if len(idxs) >= 2:\n",
        "        for i in range(len(idxs) - 1):\n",
        "            pairs.append((idxs[i], idxs[i+1]))\n",
        "            pair_labels.append(1)\n",
        "\n",
        "# Negative pairs (balanced)\n",
        "all_ids = list(id_to_indices.keys())\n",
        "while pair_labels.count(0) < pair_labels.count(1):\n",
        "    id1, id2 = random.sample(all_ids, 2)\n",
        "    pairs.append((\n",
        "        random.choice(id_to_indices[id1]),\n",
        "        random.choice(id_to_indices[id2])\n",
        "    ))\n",
        "    pair_labels.append(0)\n",
        "\n",
        "pairs = np.array(pairs)\n",
        "pair_labels = np.array(pair_labels)\n",
        "\n",
        "print(\"Pairs:\", len(pairs))\n",
        "print(\"Pair balance:\", np.unique(pair_labels, return_counts=True))\n"
      ],
      "metadata": {
        "id": "EgrVohFr0_U9",
        "outputId": "c50c9309-ff27-4dce-b39c-fd1fad5f967f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pairs: 6324\n",
            "Pair balance: (array([0, 1]), array([3162, 3162]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = np.array([\n",
        "    np.dot(embeddings[i1], embeddings[i2])\n",
        "    for i1, i2 in pairs\n",
        "])\n",
        "\n",
        "fpr, tpr, _ = roc_curve(pair_labels, scores)\n",
        "fnr = 1 - tpr\n",
        "\n",
        "idx = np.argmin(np.abs(fpr - fnr))\n",
        "eer = (fpr[idx] + fnr[idx]) / 2\n",
        "\n",
        "print(\"EER:\", eer)\n"
      ],
      "metadata": {
        "id": "ZQYGjHN61B5S",
        "outputId": "6f322047-7c97-43c7-e12b-d02646c3c7e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EER: 0.3659076533839342\n"
          ]
        }
      ]
    }
  ]
}